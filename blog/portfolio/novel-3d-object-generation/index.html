<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="Novel 3d Object Generation">
<meta itemprop="description" content="Can Computers Make Art? Of course not, you might say. They are machines! Creativity is what makes us human. Art is the epitomy of creativity, and thus the epitomy of humanity. If machines can make art, then what are we?
Let me introduce you to the Portrait of Edmond Belamy sold for $432,500 at Christie&rsquo;s art auction in October 2018. On the surface, this portrait looks like just another painting.">


<meta itemprop="datePublished" content="2019-05-22T17:32:29-07:00" />
<meta itemprop="dateModified" content="2019-05-22T17:32:29-07:00" />
<meta itemprop="wordCount" content="1771">



<meta itemprop="keywords" content="" />
<meta property="og:title" content="Novel 3d Object Generation" />
<meta property="og:description" content="Can Computers Make Art? Of course not, you might say. They are machines! Creativity is what makes us human. Art is the epitomy of creativity, and thus the epitomy of humanity. If machines can make art, then what are we?
Let me introduce you to the Portrait of Edmond Belamy sold for $432,500 at Christie&rsquo;s art auction in October 2018. On the surface, this portrait looks like just another painting." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.jackcworkman.com/blog/portfolio/novel-3d-object-generation/" />
<meta property="article:published_time" content="2019-05-22T17:32:29-07:00"/>
<meta property="article:modified_time" content="2019-05-22T17:32:29-07:00"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Novel 3d Object Generation"/>
<meta name="twitter:description" content="Can Computers Make Art? Of course not, you might say. They are machines! Creativity is what makes us human. Art is the epitomy of creativity, and thus the epitomy of humanity. If machines can make art, then what are we?
Let me introduce you to the Portrait of Edmond Belamy sold for $432,500 at Christie&rsquo;s art auction in October 2018. On the surface, this portrait looks like just another painting."/>
	<link rel="apple-touch-icon" sizes="180x180" href="/blog/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/blog/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/blog/favicon-16x16.png">
	<link rel="manifest" href="/blog/site.webmanifest">
	<link rel="mask-icon" href="/blog/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/blog/favicon.ico">

	<title>Novel 3d Object Generation</title>
	<link rel="stylesheet" href="https://www.jackcworkman.com/blog/css/style.min.9a30741782203507f3d35fe9cefabad487c72fc82dfbdf59121759fc2fa52f92.css" integrity="sha256-mjB0F4IgNQfz01/pzvq61IfHL8gt+99ZEhdZ/C+lL5I=">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://www.jackcworkman.com/blog/">Jack&#39;s Blog</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="https://www.jackcworkman.com/blog/portfolio">Portfolio</a>
					<a href="https://www.jackcworkman.com/blog/about/">About</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="mailto:jackcworkman@gmail.com" target="_blank" rel="noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mail"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg></a><a href="https://www.linkedin.com/in/jackcworkman/" target="_blank" rel="noopener" title="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-linkedin"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="https://github.com/workmanjack" target="_blank" rel="noopener" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://www.jackcworkman.com/blog/portfolio">Portfolio</a></li>
			<li><a href="https://www.jackcworkman.com/blog/about/">About</a></li>
		</ul>
	</div>


	<main class="site-main section-inner thin animated fadeIn faster">
		<h1>Novel 3d Object Generation</h1>
		<div class="content">
			

<h2 id="can-computers-make-art">Can Computers Make Art?</h2>

<p>Of course not, you might say. They are machines! Creativity is what makes us human. Art is the epitomy of creativity, and thus the epitomy of humanity. If machines can make art, then what are we?</p>

<p>Let me introduce you to the <em>Portrait of Edmond Belamy</em> sold for $432,500 at Christie&rsquo;s art auction in October 2018. On the surface, this portrait looks like just another painting. It vaguely resembles a portrait of a man but has some quirky characteristics that one might attribute to the author&rsquo;s peculiar vision - the unfinished edges, the blurry face, the studded texture. Is it worth $432,500? I&rsquo;ll leave that up to you to decide.</p>

<figure>
    <img src="/blog/800px-Edmond_de_Belamy.png"
         alt="Figure 1: Portrait of Edmond Belamy by Obvious"/> <figcaption>
            <p>Figure 1: Portrait of Edmond Belamy by Obvious</p>
        </figcaption>
</figure>


<p>Alone in the corner is a series of characters where you might normally expect an artist&rsquo;s signature. To the uninitiated, these characters resemble something that looks like a mathematical function. What a strange thing to put on a piece of art, you might say! To those familiar with deep learning neural networks, you have already figured it out. These characters spell out a network&rsquo;s loss function meaning that <em>this work of art was produced by a machine</em>.</p>

<figure>
    <img src="/blog/Edmond_de_Belamy_Loss_function.jpg"
         alt="Figure 2: Loss Function Signature of Portrait of Edmond Belamy by Obvious"/> <figcaption>
            <p>Figure 2: Loss Function Signature of Portrait of Edmond Belamy by Obvious</p>
        </figcaption>
</figure>


<p>I invite you to read <a href="https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx" target="_blank">the article on the Christie&rsquo;s website</a> for the full story behind this painting. To summarize, the <em>Portrait of Edmond Belamy</em> was produced by a French art collective known as <a href="http://obvious-art.com/" target="_blank">Obvious</a> that focuses on the boundaries between art and artificial intelligence. For this portrait, they used a type of network known as a Generative Adversarial Network (or GAN; more on these below) trained on 15,000 portraits painted between the 14th and 20th centuries.</p>

<p>With this knowledge in hand, I ask you again - can computers make art? Obvious and Christie&rsquo;s seem to think so. Or at least, they believe that algorithms can aid in the creation of art. After all, did the art come in the form of the painting or of the process the artists used to train and produce the painting? How about a musician using a backing track produced by AI? Is that laziness on the behalf of the musician or digital, new-age creativity?</p>

<p>These are the questions that inspired me to pursue the topic of Novel 3D Object Generation for the capstone project of my <a href="https://datascience.berkeley.edu/" target="_blank">Masters of Information and Data Science (MIDS)</a> program at UC Berkeley. Obvious proved the viability of AI-assisted art in the 2D space with the <em>Portrait of Edward Belamy</em>, but what about 3D art? Can data science and machine learning be utilized to produce novel 3D shapes and designs worthy of being called &ldquo;art&rdquo;?</p>

<p>In this post, I will show you, the reader, how my team and I tackled this question. We will start by first refining the question and assessing other business applications of such a system, then I&rsquo;ll introduce you to the related literature that served as inspiration for our work, and finally we&rsquo;ll walk through our approach including our successes, failures, and our final results.</p>

<h2 id="the-team">The Team</h2>

<p>Before I start talking about the project, I need to introduce and give credit to my teammates, Dave and Cynthia. <a href="https://www.linkedin.com/in/david-owen-brg/" target="_blank">Dave Owen</a> provided our team with much needed business acumen and made sure to keep us on track as the project progressed. He also deserves credit for coming up with and formulating the idea behind the project. <a href="https://www.linkedin.com/in/cynthia-yue-hu/" target="_blank">Cynthia Hu</a> and I represented the technical side of the team. Her real-world data science experience and willingness to really dig into the details of our research paper references proved invaluable throughout the project. My primary contributions were in data pipeline development, model development, and model training.</p>

<p>Dave and Cynthia were a pleasure to work with. Even in the moments of doubt where we questioned our chances of success, they hung around and listened to my crazy ideas for what we could try next. Thank you David and Cynthia!</p>

<h2 id="what-is-a-capstone-project">What is a Capstone Project?</h2>

<p>The MIDS Capstone project is part of the course <a href="https://datascience.berkeley.edu/academics/curriculum/synthetic-capstone-course/" target="_blank">W210 Synthetic Capstone</a> (I&rsquo;m not sure why it is called &ldquo;synthetic&rdquo; - it felt very real to me) and is taken at the end of a student&rsquo;s MIDS experience. The course&rsquo;s and thus project&rsquo;s goal is to give students the chance to utilize the skills they&rsquo;ve learned throughout the program to produce a real-world application or solution.</p>

<h1 id="the-project">The Project</h1>

<h2 id="refining-the-question">Refining The Question</h2>

<p>All good ideas start with a question. You&rsquo;ve just been introduced to ours: Can neural networks produce 3D objects worthy of being called art? But be warned, not all questions are good questions.</p>

<p>In our case, our question was good enough to get us started but not to drive forward progress and give us real, actionable direction. We know</p>

<p>The first project pitfall identified by both us and our instructors was the vagueness and ambiguity of art. How do you measure it? How do you determine bad from good?</p>

<h2 id="related-literature">Related Literature</h2>

<p>Call me crazy, but I enjoyed reading research papers for this project. The folks in this field are both insanely creative and incrediby clever. My impression of the papers I read were that this field is still wide open - no one&rsquo;s truly figured out how to communicate the complexities of 3D shapes to a neural network. Most papers dealt only with voxelized objects (and so did we). A few were brave enough to venture into the triangular mesh category. In this section, I cover the most influential to our project as well as one extra paper that I think is worth reading.</p>

<h2 id="working-with-3d-data">Working with 3D Data</h2>

<p>I&rsquo;d like to start this section with a question for the reader: how would you represent data in the 3D space? If you already know the answer, then skip ahead. If you don&rsquo;t, then start by thinking about how data is represented in the 2D space: an NxM grid of pixels. These pixels can be, for example in a black and white photo, a single number representing their grayscale value (the shade between black and white). Each pixel location could also contain a vector containg, for example, that pixel&rsquo;s four <a href="https://en.wikipedia.org/wiki/RGBA_color_space" target="_blank">RGBA</a> values and so on and so forth.</p>

<h3 id="voxels">Voxels</h3>

<p>If you expand the concept of the NxM grid from 2D to 3D, then you arrive at the logical data representation of the voxel grid. A <a href="https://en.wikipedia.org/wiki/Voxel" target="_blank">voxel</a> is a 3D pixel and it looks exactly as you would expect (think <a href="https://en.wikipedia.org/wiki/Minecraft" target="_blank">Minecraft</a>).</p>

<figure>
    <img src="/blog/Voxels.svg"
         alt="Figure 5: Visual example of voxels (from Wikipedia) [1]"/> <figcaption>
            <p>Figure 5: Visual example of voxels (from <a href="https://en.wikipedia.org/wiki/Voxel" target="_blank">Wikipedia</a>) [1]</p>
        </figcaption>
</figure>


<p>These voxel grids, like 2D grids, can contain a variety of data in the third dimension. For the purposes of this project and for much of the existing research in this area, that third dimension is generally populated by either a 0 or a 1 representing if a voxel exists in that space or not. This data structure is conveniently easy to use to feed to and train a neural network as many of the existing 2D algorithms can be extended and applied to the third dimension.</p>

<p>The drawback of voxel grids is the storage and thus memory space required. If a 28x28 image of an MNIST digit (from the <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank">MNIST dataset</a>) contains 28x28 ints (and we assume in this case that an int requires 4 bytes), then that image requires 28 * 28 * 4 = 3,136 bytes. With the third dimension, that single image becomes 28 * 28 * 28 * 4 = 87,808 bytes. With 70,000 digits, that increase can be pretty dramatic as illustrated in the table below.</p>

<table>
<thead>
<tr>
<th>Data</th>
<th>2D</th>
<th>3D</th>
</tr>
</thead>

<tbody>
<tr>
<td>Single digit</td>
<td>3,136 B</td>
<td>87,808 B</td>
</tr>

<tr>
<td>Full dataset</td>
<td>219.52 MB</td>
<td>6146.56 MB</td>
</tr>
</tbody>
</table>

<p>That&rsquo;s a storage/memory footprint increase of 28x (logically)! But how many pictures in the real world do you encounter that are only 28x28? Probably zero unless you do machine learning and play with the MNIST dataset. As an example, my Google Pixel 2 smartphone takes pictures that come in at a resolution of 1920x1080. Imagine adding a third dimension to that!</p>

<p>Lastly, I would be amiss if I did not mention that this project and many others rely heavily on the amazing work put into the free <a href="https://www.patrickmin.com/binvox/" target="_blank">binvox</a> application. Binvox comes as an executable packed with an astonishing number of features to support converting and manipulating voxel representations.</p>

<h3 id="triangular-meshes">Triangular Meshes</h3>

<p>If you&rsquo;ve ever watched a Pixar film or played a video game that isn&rsquo;t Minecraft, then you&rsquo;ve seen triangular meshes at work. A triangular mesh is simply a series of triangles that link together to form some type of object or plane.</p>

<figure>
    <img src="/blog/wireframe-mesh-bunny.png"
         alt="Cute example of a triangular mesh also known as a wireframe [src]"/> <figcaption>
            <p>Cute example of a triangular mesh also known as a wireframe [<a href="http://www.lix.polytechnique.fr/~maks/Verona_MPAM/TD/TD2/" target="_blank">src</a>]</p>
        </figcaption>
</figure>


<p>With a high enough &ldquo;poly count&rdquo; (poly == triangle), graphics engines can produce realistic looking images by using triangular meshes to smooth over edges and create round surfaces (as opposed to the cubic nature of voxels).</p>

<p>Meshes also improve upon the voxel&rsquo;s storage limitation. Meshes can be represented as a simple array of coordinates where (ideally) each triangular shares at least two vertices (or one edge) with another triangle. Here&rsquo;s a demonstration with a fabulous rendering via Microsoft Paint:</p>

<figure>
    <img src="/blog/triangle-mesh-example.png"
         alt="Rendering of Table N&amp;rsquo;s triangles and vertices (the artist does not have the skills required to draw in the third dimension so please do your best to imagine it) [src]"/> <figcaption>
            <p>Rendering of Table N&rsquo;s triangles and vertices (the artist does not have the skills required to draw in the third dimension so please do your best to imagine it) [<a href="http://www.lix.polytechnique.fr/~maks/Verona_MPAM/TD/TD2/" target="_blank">src</a>]</p>
        </figcaption>
</figure>


<table>
<thead>
<tr>
<th>Triangle</th>
<th>Vertex</th>
<th>X</th>
<th>Y</th>
<th>Z</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>A</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>B</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>C</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>

<tr>
<td>2</td>
<td>A</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>2</td>
<td>B</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>

<tr>
<td>2</td>
<td>C</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>The exact storage requirement of a given triangle mesh depends on (1) the number of triangles and (2) the file format. There are many file formats available - too many to list here - that offer various features like color or arcs. We focused on the formats used commonly in 3D printing and chose to start with the simplest available: the STL file.</p>

<h2 id="mesh-generation">Mesh Generation</h2>

<h3 id="data-thingi10k">Data: Thingi10k</h3>

<p><a href="https://ten-thousand-models.appspot.com/" target="_blank">The Thingi10k website</a></p>

<p><a href="https://arxiv.org/abs/1605.04797" target="_blank">The Thingi10k paper</a></p>

<h3 id="model-1-stl-vae">Model 1: STL VAE</h3>

<p>Implementation: <a href="https://github.com/workmanjack/3d-form/blob/master/src/models/stl_vae.py" target="_blank">https://github.com/workmanjack/3d-form/blob/master/src/models/stl_vae.py</a></p>

<figure>
    <img src="/blog/w210_stl-vae_squirrel-recon-orig.png"/> 
</figure>


<figure>
    <img src="/blog/w210_stl-vae_squirrel-recon-epoch00-90.gif"
         alt="Figure 1: STL VAE attempted squirrel reconstruction (top: original, bottom: reconstruction) at epochs 0 - 90"/> <figcaption>
            <p>Figure 1: STL VAE attempted squirrel reconstruction (top: original, bottom: reconstruction) at epochs 0 - 90</p>
        </figcaption>
</figure>


<h3 id="model-2-stl-gan">Model 2: STL GAN</h3>

<figure>
    <img src="/blog/w210/w210_stl-gan_box.png"
         alt="Figure 2: STL GAN output"/> <figcaption>
            <p>Figure 2: STL GAN output</p>
        </figcaption>
</figure>


<h3 id="model-3-stl-vae-gan">Model 3: STL VAE-GAN</h3>

<figure>
    <img src="/blog/w210/w210_stl-vae-gan_box.png"
         alt="Figure 2: STL GAN output"/> <figcaption>
            <p>Figure 2: STL GAN output</p>
        </figcaption>
</figure>


<h3 id="model-4-stl-rnn">Model 4: STL RNN</h3>

<p><a href="https://github.com/workmanjack/3d-form/blob/master/notebooks/SupportingFiles/stl_rnn.ipynb" target="_blank">Notebook</a></p>

<figure>
    <img src="/blog/w210_stl-rnn_output-above.png"
         alt="Figure 2: STL RNN output full view demonstrating curve of triangle stack"/> <figcaption>
            <p>Figure 2: STL RNN output full view demonstrating curve of triangle stack</p>
        </figcaption>
</figure>


<figure>
    <img src="/blog/w210_stl-rnn_output-triangles.png"
         alt="Figure 3: STL RNN output close up of triangles"/> <figcaption>
            <p>Figure 3: STL RNN output close up of triangles</p>
        </figcaption>
</figure>


<h2 id="voxel-generation">Voxel Generation</h2>

<h3 id="data-modelnet10">Data: ModelNet10</h3>

<h3 id="model-5-voxel-vae">Model 5: Voxel VAE</h3>

<h3 id="model-6-voxel-vae-gan">Model 6: Voxel VAE-GAN</h3>

<h3 id="model-7-voxel-vae-2-0">Model 7: Voxel VAE 2.0</h3>

<p>Bump to 64x64x64
Machine Upgrade</p>

<h2 id="takeaways">Takeaways</h2>

<h2 id="conclusion">Conclusion</h2>

<h2 id="resources">Resources</h2>

<ul>
<li><a href="https://github.com/workmanjack/3d-form" target="_blank">GitHub Repository</a></li>
<li><a href="https://github.com/workmanjack/3d-form/blob/master/reports/3d-mesh-mash-final-presentation.pdf" target="_blank">Final Project Presentation</a></li>
</ul>

<h2 id="references">References</h2>

<p>[1] By <a href="//commons.wikimedia.org/wiki/User:Vossman" title="User:Vossman">Vossman</a>; <a href="//commons.wikimedia.org/wiki/User:Mwtoews" title="User:Mwtoews">M. W. Toews</a> - <span class="int-own-work" lang="en">Own work</span>; originally created in <a href="https://en.wikipedia.org/wiki/Adobe_Illustrator" class="extiw" title="w:Adobe Illustrator">w:Adobe Illustrator</a>, and later in a text editor, <a href="https://creativecommons.org/licenses/by-sa/2.5" title="Creative Commons Attribution-Share Alike 2.5">CC BY-SA 2.5</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=1313585">Link</a></p>

		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2019 <a href="https://www.jackcworkman.com/blog/">Jack Workman</a> &#183; <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://www.jackcworkman.com/blog/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="https://www.jackcworkman.com/blog/js/main.min.8f39f24808e9d0a9b02da58c2d2838da859dc0b7bdfadbdb1883aae8b6adacfe.js" integrity="sha256-jznySAjp0KmwLaWMLSg42oWdwLe9+tvbGIOq6LatrP4="></script>

</body>

</html>
